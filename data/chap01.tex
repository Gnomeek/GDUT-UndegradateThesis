%!TEX root = ../main.tex
\chapter{引言}

\section{研究背景及意义}
\subsection{研究背景}
得益于摩尔定律\cite{moore1975progress}，生产电子元件的成本越来越低，电子产品的性能越来越好；同时，网速的高速发展也促进了移动互联网的进步。这两者都使得我国网民数量持续增长，用户在互联网上扮演的角色已经从单纯的信息接收者，变成现在信息的生产者。在社交媒体上，电商网站上，数亿的用户产出海量的数据，且这些数据是以指数级增长的，人工分析利用这些数据需要耗费大量的时间和人力，属于不可能的任务。但这些数据有着重要的社会价值和商业价值，如在诸如微博的这类社交媒体上，分析用户针对不同社会话题发布的微博内容，可以有效的监控网络舆情\cite{舆情监控}；而在淘宝这类电商平台上，分析用户给予不同商品的评价，商业公司可以快速了解这一商品的受欢迎程度。所以，如何通过自动化工具正确，快速分析利用这些数据，成为当今计算机科学研究领域重要的话题。

文本情感分析（Text Sentiment Analysis）作为自然语言处理（Natural Language Processing）领域的基本研究分支之一，主要任务是对文本的主客观性，观点，情绪，喜好的检测，分析，挖掘。文本情感分析作为多学科交叉研究领域，涉及语言学，统计学，机器学习，数据挖掘，人工智能等多个领域。近年来，随着机器学习的发展，学术界在情感分析技术上取得长足进步，工业界也开发许多情感分析技术落地的项目。自然语言处理于二十世纪中叶于美国兴起，主要应用场景都是针对英语。中文自然语言处理起步晚于英语，同时，中文自然语言处理也与英语有许多不同，主要表现在以下几个方面：{\large{\textcircled{\small{1}}}}中文需要进行分词；{\large{\textcircled{\small{2}}}}中文没有明显的屈折变化（时态，单复数等）；{\large{\textcircled{\small{3}}}}中英文句法结构上存在不同。但随着技术的发展和数据的爆炸式增长，作为中文自然语言处理的一个子类，提取分析非结构化文本的情感分析技术也愈发成熟。

\subsection{研究意义}
在像微博这样的社交媒体上，大量用户针对不同话题广泛发表自己的见解。这些文本通常数量庞大，依靠人力根本无法进行分析。但这些数据又有着重要的意义\cite{舆情监控,中文微博情感分析}。利用这些数据，可以迅速准确的把握微博平台上重要事件的情感倾向，有效的进行舆情监控，对政府，商业公司维持舆论稳定有着极大帮助，这时就彰显出情感分析技术的重要性。

而对于淘宝，京东这样的电商网站，它们拥有着大量的商家和消费者用户。消费者们乐于对自己喜欢的商品给予好评，对于不满意的产品也会留下差评。而这些评论对商家的发展十分重要\cite{电商网站情感分析}。根据评论，商家可以了解到顾客对于产品的喜好程度和产品的不足之处。针对这些客户意见，商家可以有针对性的对商品进行改善，提高客户满意度的同时，吸引更多的潜在客户，提高商业利润，而情感分析技术正能有效的帮助商家实现这些目的。

鉴于上述情况，本文选取微博文本数据，针对该数据集进行情感分析方法研究。尝试不同的方法来研究情感分析技术，并设计实验比较各种方法的分类结果，发掘出性能较好的分类模型，进而改善情感分类效果。


\section{国内外研究现状}
文本情感分析的核心问题是情感分类，主要研究任务分类两类，一是区分主客观文本，降低因客观信息对情感分析性能的干扰；二是对主观性文本进行情感分类\cite{杨立公2013文本情感分析综述}。根据对文本划分的粒度不同，又可分为对词，句，篇章的情感分析。根据情感划分的粒度不同，可分为：{\large{\textcircled{\small{1}}}}二元分类，包括消极态度和积极态度。{\large{\textcircled{\small{2}}}}多元分类，根据人类的多种情感进行进一步细分，包括“快乐，悲伤，褒扬，贬斥，信息，意外”等十大类\cite{杨小平2017基于}。

而对于主观文本情感分类，现在流行的方法包括以下三种：
\begin{enumerate}[1)]
\item 基于情感词典的方法。这一方法最符合人类的直觉，首先构建包含大量基本词汇的词典，词典中的词已经标记好词的类别。如“喜欢”会被标记为积极，而“讨厌”会被标记为消极。之后将输入的文本与词典进行匹配来判断其情感极性。这一方法有着局限性，通常与其他方法一同使用。
\item 基于机器学习的方法。这一方法关键点在于选择有效特征组合利用分类器进行情感分类\cite{朱晓霞2019基于主题挖掘技术的文本情感分析综述}。这一方法可以取得不错的成果，但对数据集要求很高，往往需要大量人工标注，成本不菲。
\item 基于深度学习的方法。这一方法通过建立深度神经网络，模拟人脑结构，在处理情感分类这种问题上有着优异的表现，是目前情感分析领域的主流方法。
\end{enumerate}

\subsection{国外研究现状}
对于文本主客观分类，Wiebe等\cite{wiebe1999development} 人于1999年就将代词，形容词，基数词等作为特征值，设计了对文本主客观进行分类的朴素贝叶斯分类器(Naive Bayes Classfier)。在2003年，Rlloff与Wiebe\cite{riloff2003learning}提出bootstrapping文本主客观分类算法。该算法提高分类召回率的同时，只损失部分的精度。之后，Wiebe等\cite{wilson2005recognizing}人还针对篇章粒度下的文本主客观分类进行了研究。

在情感词典技术方面，Turney\cite{10.3115/1073083.1073153}设计了点互信息的方法（Point Mutual Information, PMI)来计算两个词之间的语义相关性。通过计算目标词与情感词之间的PMI，用语义倾向(Semantic Orientation, SO)来表示该词的情感极性。公式如下：
\begin{equation}
\operatorname{PMI}\left(word_1, word_2\right)=\log _{2}\left[\frac{\mathrm{p}\left(word_1 \& word_2\right)}{\mathrm{p}\left(word_1\right) \mathrm{p}\left(word_2\right)}\right]\label{eq:PMI}
\end{equation}

\begin{equation}
\begin{aligned}
\operatorname{SO}\left(phrase\right) &=\mathrm{PMI}\left(phrase, \text{``excellent"}\right) \\
&-\mathrm{PMI}\left(phrase, \text{``poor"}\right)
\end{aligned}
\end{equation}
Hamouda等\cite{hamouda2013social}人又将在社交网络上被广泛应用的表情符号加入情感词库用于情感分析。Hu和Liu\cite{hu2004mining}在已有的情感词库的基础上，通过WordNet的同义，近义关系来判断目标情感词的情感极性。

在机器学习技术方面，Pang等\cite{pang2002thumbs}人第一次将机器学习方法引入情感分析领域，实验对比了三种机器学习方法：朴素贝叶斯(Naive Bayes)，最大熵模型(Maximum Entropy)和支持向量机(Support Vector Machine)。尽管实验结果距离这些方法应用于主题分类时的表现有些差距，但结合SVM和Unigarms特征，准确率依然有82.9\%。Kim和Hovy\cite{kim2004determining}设计算法，在给出一个主题的情况下，算法可以自动找出该主题下人们的不同意见以及意见的情感倾向。Godbole等\cite{godbole2007large}人构建了完整的情感分析系统。这一系统可以识别新闻和博客中的实体，并且计算实体对应的情感倾向，在不同数据集下的测试准确率在82.7\%至99.1\%之间。Lin和He\cite{chenghualin}提出一种与以往其他研究者不同的方法，他们基于隐含狄利克雷分配模型(Latent Dirichlet Allocation, LDA)设计了一个完全非监督的模型(joint sentiment/topic model, JST)。该模型将情感信息与LDA模型结合，实现了主题和主题相关情感信息的联合发现。通过挖掘文本中的情感和隐含的主题分布，提炼出文本的情感倾向，在不同语料下都取得很好的成果。

在深度学习技术方面，Hinton等\cite{hinton1986learning}人于1986年就提出了Distributed Representation的方法，应用于自然语言处理场景，该方法通常被成为词向量(Word Embedding)，该方法能让相似，相关的词在距离上更为接近，效果优于之前常用的N-grams技术和N-Pos技术。2013年，Mikolov等\cite{mikolov2013efficient}人终于将该方法实现，称为Word2Vec。这一方法在自然语言处理领域有着划时代的意义，后续大量研究人员的工作基本都与Word2Vec离不开关系。其中Kim\cite{kim2014convolutional}将卷积神经网络(CNN)与Word2Vec结合，进行文本情感分类。使用Word2Vec训练词向量，并在模型训练过程中保持微调，取得了良好的结果(准确率最高可达89.6\%）。之后又有新的词向量方法出现，包括Glove\cite{pennington2014glove}和fastText\cite{joulin2016fasttext}。应用于情感分类的其他深度学习模型还有循环神经网络(RNN)和RNN的变种：长短时记忆网络(LSTM)。Socher等\cite{socher2012semantic}人实现了一种矩阵向量的RNN网络(Matrix-vector Recursive Neural Network, MV-RNN)，该网络将每个词与矩阵相联系，并表示为树形结构，在长文本上结果比普通的词向量效果要好，F1值达到82.4\%，远超其他方法。Xu等\cite{xu2016cached}人实现了一种缓冲长短时记忆网络(Cached Long Short-Term Memory neural network, CLSTM)对篇章级的文本进行情感分析。通过将模型中的记忆网络分组，每组有不同的遗忘率，低遗忘率的组保持全局语义特征，高遗忘率的组用以记忆短距离语义特征。Bahdanau等\cite{bahdanau2014neural}人于2014年第一次将Attention机制引入自然语言处理领域，用以处理机器翻译任务。这给其他学者以启发，也开始将Attention机制用于自然语言处理领域的其他问题。Zhou等\cite{zhou2016attention}人将Attention机制与LSTM结合处理跨语言长文本的情感分析。在训练资源丰富的英语语料集上进行训练，使用训练资源较少的中文语料集来测试分类效果，实验显示结果良好。2018年，Peters等\cite{peters2018deep}人发表论文，提出了ELMo(Embeddings from Language Models)，一种基于大规模语料集上的预训练语言模型。这一论文让学者们发现了预训练语言模型的强大威力，随后又有像GPT(Generative Pre-training model)\cite{radford2018improving}这类模型的诞生。GPT利用Google提出的Transformer\cite{vaswani2017attention}框架中的Decoder，在各项自然语言处理任务中都取得良好的成果。直到2018年末，Google发布了BERT(Bidirectional Encoder Representations from Transformers)\cite{devlin2018bert}，刷新了自然语言处理领域内11项任务的记录，是自然语言处理领域又一里程碑式的成果。

\subsection{国内研究现状}
国内主客观文本分类研究相较国外，起步较晚。姚天昉和彭思崴\cite{__2007姚天昉}利用情感形容词，人称代词，不规范的标点符号和带情感的标点符号等作为特征，比较了四类分类算法应用于主客观分类时的性能。叶强等\cite{__2007叶强}人提出基于2-POS模型的中文文本主观性判断方法，分类性能接近英文类似研究结果。张博\cite{_svm_2011}将句法关系模块，依存关系模块与SVM分类器结合，在实验中取得良好结果，F-measure值达到88.9\%。

在情感词典方面，由于上文提到的WordNet中包含的中文词条数目远少于英文词条，因此国内多基于董振东先生、董强先生开发的知网(HowNet)进行研究。朱嫣岚等\cite{朱嫣岚2006基于}基于HowNet提供的语义相似度和语义相关场功能进行了实验。实验发现语义相似度比语义相关场能更好的进行情感分类，实验的判别准确率最高达到85.5\%。同时朱嫣岚等\cite{朱嫣岚2006基于}还发现提高基准词数量和进行词频加权都可以提高准确率。柳位平等\cite{柳位平2009中文基础情感词词典构建方法研究}人基于HowNet提供的情感词语集，通过计算词语相似度的方法建立可以跨领域使用的基础情感词语库。在这一基础情感词语库的基础上，使用改进后的TF-IDF公式(\ref{eq:TF-IDF})进行情感分类实验，准确率达到82.1\%。
\begin{equation}
w(t, \bar{d})=\frac{t f(t, \bar{d}) \times \log \left(N / n_{t}+0.01\right) \times \overline{w_{t}}}{\sqrt{\sum_{i=d}\left[t f(t, \bar{d}) \times \log \left(N / n_{t}+0,01\right) \times w_{t}\right]^{2}}}\label{eq:TF-IDF}
\end{equation}
李钝等\cite{__2008李钝}人从语言学角度出发，分析短语中词组合方式的特点，提出中心词概念来计算各词的倾向性，再由此计算短语的情感倾向性。实验结果表明，该方法对短语的倾向分类效果较好，为更大粒度的文本情感倾向识别打下基础。

在机器学习技术方面，唐慧丰等\cite{唐慧丰2007基于监督学习的中文情感分类技术比较研究}人使用n-gram，名词，形容词，动词，副词等作为文本表示特征，使用信息增益，CHI统计量，文档频率等作为特征选择方法，在中心向量法，KNN，Winnow，Naive Bayes，SVM这些机器学习方法上测试了情感分类效果。结果表示，结合BiGrams，信息增益和SVM的分类效果明显高于其他方法。同时，提高训练集大小和选取适当数量的特征均能提升表现。徐军等\cite{徐军2007使用机器学习方法进行新闻的情感自动分类}人使用朴素贝叶斯模型和最大熵模型对新闻及评论语料集进行了情感分类研究，其中最大熵模型结果更好。实验发现选择具有语义倾向的词汇和使用二值作为特征项权重能有效提高分类准确率。韦航和王永恒\cite{韦航2015基于主题的中文微博情感分析}使用SVM中的卷积树核函数获取语法树的结构化特征，对语法树进行基于主题的剪枝，可以有效提高情感分类准确度，在两个数据集上准确度均可达到86\%以上。

在深度学习技术方面，国内学者也大多采用国外学者类似的方法，针对中文语言进行特色性优化。华中科技大学的曾江峰\cite{__2019zengjiangfeng}提出一种可以感知句法语义的文本情感算法，在篇章级的文本上取得良好效果。该算法首先对每个句子的依存句法树生成Tree-LSTM，再利用基于Attention机制的LSTM网络来获取篇章级的情感倾向。李然\cite{__2015liran}实现了基于深度神经网络(Deep Neural Network, DNN)的短文本情感分类算法，在大规模电商评论数据集上的实验结果优于主题模型。胡朝举和赵晓伟\cite{胡朝举2018基于词向量技术和混合神经网络的情感分析}基于词向量技术，将CNN与LSTM融合形成混合神经网络，其中LSTM被更换为基于Attention机制的双向LSTM网络(BILSTM)，在IMDB数据集上取得了89.6\%的准确度。张仰森等\cite{张仰森2018基于双重注意力模型的微博情感分析方法}人提出一种基于双重注意力机制的微博情感分析方法。该方法结合微博特有的情感符号和注意力机制，有效提升了微博文本情感信息的获取。在自然语言处理与中文计算会议(NLPCC)于2014年发布的微博情感测评公共数据集上，相较当时已知的最好模型，将宏平均和微平均的F1值分别提升了2.02\%和2.21\%。赵亚欧等\cite{_elmo_nodate}人将ELMo模型应用于中文情感分析场景，提出一种融合ELMo模型的多尺度卷积神经网络(Multi-Scale Convolutional Neural Network, MSCNN)。使用不同尺度的卷积核对文本进行卷积处理，利用最大池化技术筛选获取到的特征，将这些特征融合以获得最终的文本特征。该模型在酒店评论数据集和NLPCC于2014年提供的任务2数据集上均表现良好，与之前学者在相同数据集上的训练效果相比，有着长足进步。蔡国永等\cite{_bert_2020}人使用BERT模型抽取句子语义表示为向量，通过CNN来获取句子局部特征，最后使用域对抗神经网络让源领域和目标领域抽取的特征更为相似，以实现跨领域情感分析的目的。在针对亚马逊产品评论数据集的实验下表现良好，准确率可达89.9\%。

\section{本文研究内容}
本文主要工作包括以下几个方面的内容：基于情感词典的情感分析方法，基于机器学习的情感分析方法，基于深度学习的情感分析方法。本文使用的数据集为带标注的开源微博数据集\cite{数据集}，数据量约为120,000条。实验验证，TODO。三种方法的具体内容如下：
\begin{enumerate}[1)]
\item 基于情感词典的方法。基于该方法的情感分析依赖于情感词典的大小，本文在基础情感词典上，针对本文使用的微博数据集，对情感词典进行针对性扩展，有效改善了分类效果。
\item 基于机器学习的方法。
\item 基于深度学习的方法。
\end{enumerate}

\section{论文组织结构}
本文共分为六个章节，论文的具体结构和每个章节涵盖的内容如下：

第一章：引言。本章节简单介绍了文本情感分析的背景，研究意义和对国内外学者针对文本情感分析做出的研究。接着简单介绍本文的主要研究内容，最后介绍论文的组织结构。

第二章：相关技术介绍。该章介绍了本文使用到的一些文本情感分析技术，并对原理进行简单阐述。

第三章：基于情感词典的情感分析。本章介绍了使用情感词典进行情感分析的方法。在该章中我们建立和扩展了基础情感词典，通过实验对比，发现扩展情感词典规模可以有效提高情感分类效果，在对照实验中，规模最大的情感词典准确率达到了75.35\%，比起最小的情感词典，准确率提高约了6个百分点。

第四章：基于机器学习的情感分析。本章研究了如何使用支持向量机（SVM）进行情感分析，TODO：实验结果

第五章：基于BERT模型的情感分析。本章使用自然语言处理最前沿的BERT预处理语言模型进行情感分析，TODO：实验结果

第六章：实验设计和成果分析。基于数据集设计实验，分析比较上述方法在数据集上的表现效果，对结果进行分析。
